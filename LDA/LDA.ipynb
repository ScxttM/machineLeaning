{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tarea 1 - Análisis discriminante lineal</h1>\n",
    "<h4>Universidad autónoma de Baja California<br>\n",
    "Aprendizaje automático, Dr. Luis Pellegrin<br>\n",
    "Alan Montesinos Scott</h4>\n",
    "\n",
    "<p><strong>Descripción: </strong> la actividad consiste en aplicación del discriminante lineal en un conjunto de datos controlado.\n",
    "\n",
    "Elaborar un reporte que presente el código desarrollado, tomando en cuenta las especificaciones abajo descritas. La extensión del reporte es variable y debe contener los datos del alumno, título de la tarea, y datos de la clase. Además debe presentar una discusión en torno a las diferentes especificaciones solicitadas. Incluir al final del reporte una reflexión personal de la tarea.\n",
    "\n",
    "<strong>Especificaciones a tomar en cuenta:</strong>\n",
    "\n",
    "Generar mínimo 50 datos aleatorios, compuestos por dos variables.\n",
    "Graficar datos para verificar que existe una separación visible, y etiquetar dos diferentes clases.\n",
    "Generar y graficar dos discriminantes lineales:\n",
    "Separa correctamente las clases (o su mayoría).\n",
    "Separa incorrectamente las clases (o su mayoría).\n",
    "Graficar ambos discrinantes con los datos generados.\n",
    "Generar una matriz de confusión para cada discriminante lineal.\n",
    "Generar los resultados de aplicación de métricas de evaluación para los dos discriminantes lineales tomando en consideración las dos clases: accuracy, precision, recall, F1.<p>\n",
    "\n",
    "\n",
    "<h4>Introducción</h4>\n",
    "<p>El Análisis Discriminante Lineal o Linear Discrimiant Analysis (LDA) es un método de clasificación supervisado de variables cualitativas en el que dos o más grupos son conocidos a priori y nuevas observaciones se clasifican en uno de ellos en función de sus características. Haciendo uso del teorema de Bayes, LDA estima la probabilidad de que una observación, dado un determinado valor de los predictores, pertenezca a cada una de las clases de la variable cualitativa, P(Y=k|X=x). Finalmente se asigna la observación a la clase k para la que la probabilidad predicha es mayor.</p>\n",
    "\n",
    "<h4>Desarrollo</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "class point:\n",
    "  def __init__(self,x,y,color,group):\n",
    "      self.color=color\n",
    "      self.group=group\n",
    "      self.x=x\n",
    "      self.y=y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generó 50 puntos de manera aleatoria, compuestos por dos variables. Para etiquetar en dos clases diferentes, se optó por marcar como \"red\" (rojo) a los puntos por debajo de la función identidad, y como \"blue\" aquellos por encima de ésta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "\n",
    "for x in range(50):\n",
    "  x=random.randint(0,50)\n",
    "  y=random.randint(0,50)\n",
    "  if y <= x:\n",
    "    color = 'red'\n",
    "    points.append(point(x,y,color,''))\n",
    "  else:\n",
    "    color = 'blue'\n",
    "    points.append(point(x,y,color,''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se graficaron dos discriminantes lineales:<br>\n",
    "a. Separa correctamente las clases (o su mayoría).<br>\n",
    "b. Separa incorrectamente las clases (o su mayoría)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,m,b):\n",
    "    return m*x+b\n",
    "\n",
    "m = random.randint(0,5)\n",
    "b = random.randint(0,10)\n",
    "x = range(0,50)\n",
    "plt.plot(x,[f(i,m,b) for i in x])\n",
    "\n",
    "for point in points:\n",
    "    plt.scatter(point.x,point.y, color=point.color)\n",
    "\n",
    "plt.ylim([0,53])\n",
    "plt.xlim([0,53])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos son los siguientes:<br>\n",
    "a.<br>\n",
    "![](correcta.png)\n",
    "\n",
    "b.<br>\n",
    "![](incorrecta.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import positive\n",
    "\n",
    "\n",
    "def fx(y,m,b):\n",
    "  return (y-b)/m \n",
    "\n",
    "TP=0\n",
    "FP=0\n",
    "TN=0\n",
    "FN=0\n",
    "\n",
    "actual = []\n",
    "predicted = []\n",
    "\n",
    "for point in points:\n",
    "  if point.x < fx(point.y,m,b):\n",
    "    if point.color=='blue':\n",
    "      TN +=1\n",
    "      actual.append(\"blue\")\n",
    "      predicted.append(\"blue\")\n",
    "    else:\n",
    "      FN +=1\n",
    "      actual.append(\"red\")\n",
    "      predicted.append(\"blue\")\n",
    "  else:\n",
    "    if point.color=='red':\n",
    "      TP +=1\n",
    "      actual.append(\"red\")\n",
    "      predicted.append(\"red\")\n",
    "    else:\n",
    "      FP +=1\n",
    "      actual.append(\"red\")\n",
    "      predicted.append(\"blue\")\n",
    "\n",
    "data = {\n",
    "  \"actual\" : actual,\n",
    "  \"predicted\" : predicted\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, columns=['actual', 'predicted'])\n",
    "\n",
    "confusion_matrix = pd.crosstab(df['actual'], df['predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Matriz de confusión</h4>\n",
    "\n",
    "a.<br>\n",
    "![](correcta_confusion_matrix.png)<br>\n",
    "\n",
    "b.<br>\n",
    "![](incorrecta_confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP+TN)/(TP+FN+TN+FP)\n",
    "precision = TP/(FP+TP)\n",
    "recall = TP/(FN+TP)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Precision: ',precision)\n",
    "print('Recall: ',recall)\n",
    "print('F1: ',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Resultados</h4>\n",
    "<p>\n",
    "a.<br>\n",
    "Accuracy:  1.0<br>\n",
    "Precision:  1.0<br>\n",
    "Recall:  1.0<br>\n",
    "F1:  1.0<br>\n",
    "\n",
    "b.<br>\n",
    "Accuracy:  0.72<br>\n",
    "Precision:  0.6410256410256411<br>\n",
    "Recall:  1.0<br>\n",
    "F1:  0.7812500000000001<br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Conclusión</h4>\n",
    "<p>\n",
    "El análisis discriminante lineal nos permite clasificar grupos bajo supervisión. De tal manera se le puede entrenar a una máquina a reconocer los resultados que son \"true positives\" y diferenciarlos de los \"false positives\", haciendo la clasificación más precisa.\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cbb33fb0dd98d60d7542c1e0a8ec9389a1bc71302aaca21e62e688716f63114"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
